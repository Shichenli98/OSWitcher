{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fft_conv_pytorch import fft_conv, FFTConv1d, FFTConv2d\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNet = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3,2,5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(2,1,3),\n",
    "    torch.nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(myNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Sequential                               [1, 44, 44]               --\n",
      "├─Conv2d: 1-1                            [2, 46, 46]               152\n",
      "├─ReLU: 1-2                              [2, 46, 46]               --\n",
      "├─Conv2d: 1-3                            [1, 44, 44]               19\n",
      "├─ReLU: 1-4                              [1, 44, 44]               --\n",
      "==========================================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.01\n",
      "==========================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.08\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "mySummary = summary(myNet, (3, 50, 50))\n",
    "print(mySummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv = myNet[0]\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 44]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySummary.summary_list[0].output_size[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.SyncBatchNorm.convert_sync_batchnorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_convert_opt_conv2d(module, threshold):\n",
    "    module_output = module\n",
    "    for i, layer in enumerate(list(myNet.children())):\n",
    "        if isinstance(layer, torch.nn.Conv2d):\n",
    "            if layer.kernel_size[0] > threshold:\n",
    "                module_output[i] = FFTConv2d(in_channels=layer.in_channels, \n",
    "                                             out_channels=layer.out_channels,\n",
    "                                             kernel_size=layer.kernel_size, \n",
    "                                             stride=layer.stride,\n",
    "                                             padding=layer.padding,\n",
    "                                             padding_mode=layer.padding_mode,\n",
    "                                             dilation=layer.dilation,\n",
    "                                             groups=layer.groups,\n",
    "                                             bias=True if layer.bias is not None else False)\n",
    "    del module\n",
    "    return module_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): _FFTConv()\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "myNet_opt = hard_convert_opt_conv2d(myNet, 4)\n",
    "print(myNet_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More candidates for convolution and matmul"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
